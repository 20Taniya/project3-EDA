{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5eb7dc-5a39-45eb-b3db-be8e02db41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e05fb86-c235-40b0-a135-7719c8f799cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "DATA_PATH = DATA_PATH = r\"C:\\Users\\Lenovo\\Downloads\\housing_data (1).csv\"\n",
    "OUTPUT_DIR = 'eda_outputs'\n",
    "CURRENT_YEAR = datetime.now().year\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2fbe34f-55e8-4b8e-a359-d3c19aa55e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV (or Excel) into a DataFrame.\"\"\"\n",
    "    if path.endswith('.csv'):\n",
    "        return pd.read_csv(path)\n",
    "    elif path.endswith(('.xls', '.xlsx')):\n",
    "        return pd.read_excel(path)\n",
    "    else:\n",
    "        raise ValueError('Unsupported file format. Use CSV or Excel.')\n",
    "\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    path = os.path.join(OUTPUT_DIR, name)\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37164b8d-5e6a-4730-b832-fd9cf647cb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from C:\\Users\\Lenovo\\Downloads\\housing_data (1).csv\n",
      "Initial rows: 1460 columns: 81\n",
      "\n",
      "Columns:\n",
      "['Unnamed: 0', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n",
      "\n",
      "Data types:\n",
      "Unnamed: 0        int64\n",
      "MSSubClass       object\n",
      "MSZoning         object\n",
      "LotFrontage       int64\n",
      "LotArea           int64\n",
      "                  ...  \n",
      "MoSold           object\n",
      "YrSold            int64\n",
      "SaleType         object\n",
      "SaleCondition    object\n",
      "SalePrice         int64\n",
      "Length: 81, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the data\n",
    "# -----------------------------\n",
    "print('Loading data from',DATA_PATH )\n",
    "try:\n",
    "    df = load_data(DATA_PATH)\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Failed to load data: {e}\")\n",
    "\n",
    "print('Initial rows:', df.shape[0], 'columns:', df.shape[1])\n",
    "\n",
    "# Quick peek\n",
    "print('\\nColumns:')\n",
    "print(df.columns.tolist())\n",
    "print('\\nData types:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a676d3-b9c4-4d2f-b15b-b4b72aa1b593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Renamed columns to standardized format.\n",
      "Dropped 0 duplicate rows\n",
      "\n",
      "Top missing values:\n",
      "alley          1369\n",
      "masvnrtype      872\n",
      "garageyrblt      81\n",
      "electrical        1\n",
      "dtype: int64\n",
      "\n",
      "Detected price-like columns: ['saleprice']\n",
      "Detected area-like columns: ['lotarea', 'masvnrarea', 'grlivarea', 'garagearea', 'poolarea']\n",
      "Dropped 0 rows missing price or area\n",
      "\n",
      "After cleaning, dataset shape: (1460, 81)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data cleaning\n",
    "# -----------------------------\n",
    "# 2.1 Standardize column names\n",
    "orig_cols = df.columns.tolist()\n",
    "cols = [c.strip().lower().replace(' ', '_').replace('(', '').replace(')', '') for c in orig_cols]\n",
    "rename_map = dict(zip(orig_cols, cols))\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "print('\\nRenamed columns to standardized format.')\n",
    "\n",
    "# 2.2 Remove exact duplicates\n",
    "before_dup = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "after_dup = df.shape[0]\n",
    "print(f'Dropped {before_dup - after_dup} duplicate rows')\n",
    "\n",
    "# 2.3 Identify missingness\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print('\\nTop missing values:')\n",
    "print(missing[missing > 0].head(20))\n",
    "\n",
    "# Strategy (generic):\n",
    "# - If a critical numeric column (price, area) has missing -> drop or impute with median\n",
    "# - If categorical -> fill with 'Unknown' or mode\n",
    "\n",
    "# Guess common column names; adapt if dataset differs\n",
    "possible_price_cols = [c for c in df.columns if 'price' in c]\n",
    "possible_area_cols = [c for c in df.columns if any(x in c for x in ['area', 'sqft', 'size', 'built_up'])]\n",
    "print('\\nDetected price-like columns:', possible_price_cols)\n",
    "print('Detected area-like columns:', possible_area_cols)\n",
    "\n",
    "# We'll pick first matches if available\n",
    "price_col = possible_price_cols[0] if possible_price_cols else None\n",
    "area_col = possible_area_cols[0] if possible_area_cols else None\n",
    "\n",
    "if price_col is None or area_col is None:\n",
    "    print('\\nWarning: Could not auto-detect price or area columns. Please update the script with the correct column names.')\n",
    "\n",
    "# Convert price & area to numeric\n",
    "if price_col:\n",
    "    df[price_col] = pd.to_numeric(df[price_col], errors='coerce')\n",
    "if area_col:\n",
    "    df[area_col] = pd.to_numeric(df[area_col], errors='coerce')\n",
    "\n",
    "# Drop rows missing both price and area - cannot usefully analyze\n",
    "if price_col and area_col:\n",
    "    before = df.shape[0]\n",
    "    df = df.dropna(subset=[price_col, area_col], how='any')\n",
    "    after = df.shape[0]\n",
    "    print(f'Dropped {before-after} rows missing price or area')\n",
    "\n",
    "# Impute numeric columns with median\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "if len(numeric_cols) > 0:\n",
    "    df[numeric_cols] = pd.DataFrame(num_imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# Fill categorical NaNs with 'Unknown'\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].fillna('Unknown')\n",
    "\n",
    "print('\\nAfter cleaning, dataset shape:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ecd58f-087d-4a4c-b1f7-073ffab4089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Univariate analysis\n",
    "# -----------------------------\n",
    "# Price distribution\n",
    "if price_col:\n",
    "    fig = plt.figure()\n",
    "    sns.histplot(df[price_col], kde=True)\n",
    "    plt.title('Distribution of Price')\n",
    "    save_fig(fig, 'price_distribution.png')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    sns.boxplot(x=df[price_col])\n",
    "    plt.title('Price Boxplot (to show outliers)')\n",
    "    save_fig(fig, 'price_boxplot.png')\n",
    "\n",
    "# Area distribution\n",
    "if area_col:\n",
    "    fig = plt.figure()\n",
    "    sns.histplot(df[area_col], kde=True)\n",
    "    plt.title('Distribution of Area')\n",
    "    save_fig(fig, 'area_distribution.png')\n",
    "\n",
    "# Categorical value counts (top categories)\n",
    "for c in cat_cols[:6]:\n",
    "    fig = plt.figure()\n",
    "    sns.countplot(y=c, data=df, order=df[c].value_counts().iloc[:15].index)\n",
    "    plt.title(f'Top categories for {c}')\n",
    "    save_fig(fig, f'count_{c}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed48b779-7542-4424-bdf3-ce9f717b4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Multivariate analysis\n",
    "# -----------------------------\n",
    "# Correlation heatmap for numeric features\n",
    "if len(numeric_cols) > 1:\n",
    "    corr = df[numeric_cols].corr()\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    save_fig(fig, 'correlation_matrix.png')\n",
    "\n",
    "# Scatter plot price vs area\n",
    "if price_col and area_col:\n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x=df[area_col], y=df[price_col])\n",
    "    plt.title('Price vs Area')\n",
    "    save_fig(fig, 'price_vs_area.png')\n",
    "\n",
    "# Price by bedrooms/bathrooms if columns exist\n",
    "bed_cols = [c for c in df.columns if 'bed' in c]\n",
    "bath_cols = [c for c in df.columns if 'bath' in c]\n",
    "\n",
    "if bed_cols:\n",
    "    b = bed_cols[0]\n",
    "    fig = plt.figure()\n",
    "    sns.boxplot(x=b, y=price_col, data=df)\n",
    "    plt.title('Price by Number of Bedrooms')\n",
    "    save_fig(fig, 'price_by_bedrooms.png')\n",
    "    \n",
    "if bath_cols:\n",
    "    b = bath_cols[0]\n",
    "    fig = plt.figure()\n",
    "    sns.boxplot(x=b, y=price_col, data=df)\n",
    "    plt.title('Price by Number of Bathrooms')\n",
    "    save_fig(fig, 'price_by_bathrooms.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82ff7695-fc6d-438b-8b47-1f36925f0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved engineered features: ['price_per_sqft', 'property_age', 'has_pool', 'has_garage', 'has_parking', 'has_balcony', 'has_garden', 'has_gym']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Feature engineering\n",
    "# -----------------------------\n",
    "# Price per sqft\n",
    "if price_col and area_col:\n",
    "    df['price_per_sqft'] = df[price_col] / df[area_col].replace({0: np.nan})\n",
    "    df['price_per_sqft'].fillna(df['price_per_sqft'].median(), inplace=True)\n",
    "\n",
    "# Age of property from year_built or built_year columns\n",
    "year_cols = [c for c in df.columns if any(x in c for x in ['year', 'built', 'construction'])]\n",
    "if year_cols:\n",
    "    ycol = year_cols[0]\n",
    "    # ensure numeric\n",
    "    df[ycol] = pd.to_numeric(df[ycol], errors='coerce')\n",
    "    df['property_age'] = CURRENT_YEAR - df[ycol]\n",
    "    df['property_age'] = df['property_age'].clip(lower=0)\n",
    "else:\n",
    "    df['property_age'] = np.nan\n",
    "\n",
    "# Binary flags for common amenities\n",
    "amenities = ['pool', 'garage', 'parking', 'balcony', 'garden', 'gym']\n",
    "for a in amenities:\n",
    "    cols_with_a = [c for c in df.columns if a in c]\n",
    "    if cols_with_a:\n",
    "        c0 = cols_with_a[0]\n",
    "        df[f'has_{a}'] = df[c0].astype(str).str.lower().apply(lambda x: 1 if x not in ['none', 'no', '0', 'unknown', 'nan'] and x.strip() else 0)\n",
    "    else:\n",
    "        df[f'has_{a}'] = 0\n",
    "\n",
    "# Save engineered feature snapshot\n",
    "feats_to_save = ['price_per_sqft', 'property_age'] + [f'has_{a}' for a in amenities if f'has_{a}' in df.columns]\n",
    "feats_existing = [f for f in feats_to_save if f in df.columns]\n",
    "df[feats_existing].to_csv(os.path.join(OUTPUT_DIR, 'engineered_features.csv'), index=False)\n",
    "print('\\nSaved engineered features:', feats_existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb5c54c0-d457-4279-a22a-bea551e89e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans clustering done with features: ['saleprice', 'lotarea', 'price_per_sqft']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Clustering on numeric features (KMeans)\n",
    "# -----------------------------\n",
    "cluster_features = [price_col, area_col, 'price_per_sqft'] if price_col and area_col else numeric_cols[:3]\n",
    "cluster_features = [c for c in cluster_features if c in df.columns]\n",
    "cluster_df = df[cluster_features].copy().dropna()\n",
    "\n",
    "if len(cluster_features) >= 2 and cluster_df.shape[0] >= 10:\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(cluster_df)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    cluster_df['cluster'] = labels\n",
    "    # Merge back a small sample label column\n",
    "    df.loc[cluster_df.index, 'cluster_label'] = labels\n",
    "    fig = plt.figure()\n",
    "    sns.scatterplot(x=cluster_df[cluster_features[1]], y=cluster_df[cluster_features[0]], hue=cluster_df['cluster'], palette='deep')\n",
    "    plt.title('KMeans clusters')\n",
    "    save_fig(fig, 'kmeans_clusters.png')\n",
    "    print('KMeans clustering done with features:', cluster_features)\n",
    "else:\n",
    "    print('Not enough numeric features or rows for clustering. Skipping KMeans.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc3b758d-0133-459f-8cb8-4d40d36dd00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression results: RMSE=68244.55, R2=0.393\n",
      "Saved linear regression coefficients to lr_coefficients.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 7. Simple predictive model: Linear Regression\n",
    "# -----------------------------\n",
    "# Use a small subset of features\n",
    "model_features = []\n",
    "if area_col:\n",
    "    model_features.append(area_col)\n",
    "if 'price_per_sqft' in df.columns:\n",
    "    model_features.append('price_per_sqft')\n",
    "if 'property_age' in df.columns:\n",
    "    model_features.append('property_age')\n",
    "# add numeric amenity flags\n",
    "model_features += [f'has_{a}' for a in amenities if f'has_{a}' in df.columns]\n",
    "model_features = [m for m in model_features if m in df.columns]\n",
    "\n",
    "if price_col and len(model_features) >= 1:\n",
    "    X = df[model_features]\n",
    "    y = df[price_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    preds = lr.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f'Linear Regression results: RMSE={rmse:.2f}, R2={r2:.3f}')\n",
    "    # Coefficients\n",
    "    coef_df = pd.DataFrame({'feature': model_features, 'coefficient': lr.coef_})\n",
    "    coef_df.to_csv(os.path.join(OUTPUT_DIR, 'lr_coefficients.csv'), index=False)\n",
    "    print('Saved linear regression coefficients to lr_coefficients.csv')\n",
    "else:\n",
    "    print('Insufficient data to train linear regression. Need price column and at least one feature.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d7dc7c7-2d17-4fcf-b908-c4063f4f7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8. Market trends (time-series)\n",
    "# -----------------------------\n",
    "# If there's a transaction_date or year column, aggregate by year/month\n",
    "date_cols = [c for c in df.columns if 'date' in c or 'transaction' in c or 'sold' in c]\n",
    "if date_cols:\n",
    "    dcol = date_cols[0]\n",
    "    try:\n",
    "        df[dcol] = pd.to_datetime(df[dcol], errors='coerce')\n",
    "        df['year_month'] = df[dcol].dt.to_period('M')\n",
    "        ts = df.groupby('year_month')[price_col].median().reset_index()\n",
    "        ts['year_month'] = ts['year_month'].dt.to_timestamp()\n",
    "        fig = plt.figure()\n",
    "        sns.lineplot(x='year_month', y=price_col, data=ts)\n",
    "        plt.title('Median Price over Time')\n",
    "        plt.xticks(rotation=45)\n",
    "        save_fig(fig, 'price_over_time.png')\n",
    "    except Exception as e:\n",
    "        print('Failed to parse date column for time-series:', e)\n",
    "else:\n",
    "    print('No obvious date column found for time-series analysis.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3e7b2c-a615-495c-a771-f96049909dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amenity impact for pool:\n",
      "   has_pool  count    median          mean\n",
      "0         1   1460  163000.0  180921.19589\n",
      "\n",
      "Amenity impact for garage:\n",
      "   has_garage  count    median           mean\n",
      "0           0     81  100000.0  103317.283951\n",
      "1           1   1379  167500.0  185479.511240\n",
      "\n",
      "Amenity impact for parking:\n",
      "   has_parking  count    median          mean\n",
      "0            0   1460  163000.0  180921.19589\n",
      "\n",
      "Amenity impact for balcony:\n",
      "   has_balcony  count    median          mean\n",
      "0            0   1460  163000.0  180921.19589\n",
      "\n",
      "Amenity impact for garden:\n",
      "   has_garden  count    median          mean\n",
      "0           0   1460  163000.0  180921.19589\n",
      "\n",
      "Amenity impact for gym:\n",
      "   has_gym  count    median          mean\n",
      "0        0   1460  163000.0  180921.19589\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 9. Amenity impact analysis example\n",
    "# -----------------------------\n",
    "for a in amenities:\n",
    "    col = f'has_{a}'\n",
    "    if col in df.columns:\n",
    "        agg = df.groupby(col)[price_col].agg(['count', 'median', 'mean']).reset_index()\n",
    "        print(f\"\\nAmenity impact for {a}:\")\n",
    "        print(agg)\n",
    "        agg.to_csv(os.path.join(OUTPUT_DIR, f'amenity_impact_{a}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b267e12-b1df-49fc-afc7-f7fd73a86490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved cleaned dataset to eda_outputs\\cleaned_housing_data.csv\n",
      "\n",
      "EDA complete. Visualizations and artifacts saved in the directory: eda_outputs\n",
      "Check the files (png, csv, summary.txt) for the outputs.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 10. Save cleaned dataset & summary\n",
    "# -----------------------------\n",
    "clean_path = os.path.join(OUTPUT_DIR, 'cleaned_housing_data.csv')\n",
    "df.to_csv(clean_path, index=False)\n",
    "print('\\nSaved cleaned dataset to', clean_path)\n",
    "\n",
    "summary = {\n",
    "    'initial_rows': before_dup,\n",
    "    'final_rows': df.shape[0],\n",
    "    'num_numeric_cols': len(numeric_cols),\n",
    "    'num_categorical_cols': len(cat_cols)\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'summary.txt'), 'w') as f:\n",
    "    for k, v in summary.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "\n",
    "print('\\nEDA complete. Visualizations and artifacts saved in the directory:', OUTPUT_DIR)\n",
    "print('Check the files (png, csv, summary.txt) for the outputs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c75af8-b286-43da-8124-56363f258426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
